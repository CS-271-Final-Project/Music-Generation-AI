{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from  tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parses the dataset and maps notes to unique symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_songs(data_dir, sample_length):\n",
    "    note_sequence = []\n",
    "    note_to_int = {}\n",
    "    \n",
    "    symbol = 0\n",
    "    \n",
    "    for data_file in os.listdir(data_dir):\n",
    "        current_song = open(data_dir + \"\\\\\" + data_file,'r')\n",
    "        \n",
    "        for chord in current_song:\n",
    "            note_processed = chord.replace(\"\\n\",\"\")\n",
    "            \n",
    "            if not note_processed in note_to_int:\n",
    "                note_to_int[note_processed] = symbol\n",
    "                symbol += 1\n",
    "            \n",
    "            note_sequence.append(note_to_int[note_processed])\n",
    "            \n",
    "            if len(note_sequence) >= sample_length:\n",
    "                return (note_sequence, note_to_int)\n",
    "    \n",
    "    return (note_sequence, note_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates a model with 3 LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "def build_model2(shape, n_vocab):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(\n",
    "        256,\n",
    "        input_shape=shape,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.LSTM(512, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.LSTM(256))\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(n_vocab))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pairs of note sequences and expected outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "def generate_training_pairs(sequence, sequence_length, n_vocab):\n",
    "    training_inputs = []\n",
    "    expected_outputs = []\n",
    "    \n",
    "    for i in range(0, len(sequence) - sequence_length):\n",
    "        training_inputs.append(sequence[i:i + sequence_length])\n",
    "        expected_outputs.append(sequence[i + sequence_length])\n",
    "    \n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    n_patterns = len(training_inputs)\n",
    "    training_inputs = np.reshape(training_inputs, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    training_inputs = training_inputs / float(n_vocab)\n",
    "    expected_outputs = tf.keras.utils.to_categorical(expected_outputs) \n",
    "    \n",
    "    return (training_inputs, expected_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample a probability from the list with some randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://stackoverflow.com/questions/54030842/character-lstm-keeps-generating-same-character-sequence \n",
    "# to test if this resolves the repeating character issue\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse the keys and values of a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_dict(dictionary):\n",
    "    output = {}\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        output[value] = key\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exports a list to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_list(sequence, file_name, dir_name):\n",
    "    f = open(dir_name + \"\\\\\" + file_name, \"a\")\n",
    "    \n",
    "    for item in sequence:\n",
    "        f.write(item + \"\\n\")\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a checkpoint object and the corresponding directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "def create_checkopint(epochs, sample_length, sequence_length):\n",
    "    dir_name = \"epochs_\" + str(epochs) +\"_samp_length_\" + str(sample_length) + \"_seq_length_\" + str(sequence_length) \n",
    "    sub_dir = \"\\\\model_checkpoints\"\n",
    "    \n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    if not os.path.isdir(dir_name+sub_dir):\n",
    "        os.mkdir(dir_name + sub_dir)\n",
    "    \n",
    "    filepath = dir_name + sub_dir+ \"\\\\weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    \n",
    "    # Save the model after training for the specified number of epochs\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath, monitor = 'loss', \n",
    "        verbose = 0,        \n",
    "        save_best_only = False,\n",
    "        save_freq='epoch',\n",
    "        period=epochs,\n",
    "        mode = 'min'\n",
    "    )\n",
    "    \n",
    "    return [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a model to generate new songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(model, sequence_length, num_notes, int_to_note):\n",
    "    song = []\n",
    "    input_sequence = []\n",
    "    \n",
    "    # Randomly generate the input sequence\n",
    "    for item in range(sequence_length):\n",
    "        input_sequence.append(np.random.randint(0, num_notes-1))\n",
    "\n",
    "    for note_index in range(100):\n",
    "        # Predict the next note\n",
    "        prediction_input = np.reshape(input_sequence, (1, len(input_sequence), 1))\n",
    "        prediction_input = prediction_input / float(num_notes)    \n",
    "        prediction = model.predict(prediction_input, verbose=0) \n",
    "        \n",
    "        # Convert the note from an int to a string\n",
    "        index = sample(prediction[0], temperature=0.4)\n",
    "        result = int_to_note[index]\n",
    "        song.append(result)\n",
    "        \n",
    "        # Add the note to the input sequence\n",
    "        input_sequence = np.append(input_sequence, index)\n",
    "        input_sequence = input_sequence[1:len(input_sequence)]\n",
    "    \n",
    "    return song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model and generate songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_songs(sample_length, data_dir, sequence_length,epochs, num_songs):\n",
    "    # Parse the csv files in the dataset into a sequence of integers\n",
    "    (songs, note_to_int) = parse_songs(data_dir, sample_length)\n",
    "    num_notes = len(note_to_int)\n",
    "    \n",
    "    # Reverse the map for decoding integers into notes\n",
    "    int_to_note = reverse_dict(note_to_int)\n",
    "    \n",
    "    # Generate pairs of note sequences and the expected next note\n",
    "    (training_inputs, expected_outputs) = generate_training_pairs(songs, sequence_length, num_notes)\n",
    "    \n",
    "    # Create and train a model\n",
    "    callbacks_list = create_checkopint(epochs, sample_length, sequence_length)\n",
    "    model = build_model2(training_inputs.shape[1:], num_notes)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    model.fit(training_inputs, expected_outputs, epochs=epochs, batch_size=64, callbacks=callbacks_list)\n",
    "    \n",
    "    # Generate songs with the model\n",
    "    generated_songs = []\n",
    "    for i in range(num_songs):\n",
    "        song = generate_song(model, sequence_length, num_notes, int_to_note)\n",
    "        generated_songs.append(song)\n",
    "        print(i)\n",
    "    \n",
    "    # Export the songs\n",
    "    for song in range(len(generated_songs)):\n",
    "        dir_name = \"epochs_\" + str(epochs) +\"_samp_length_\" + str(sample_length) + \"_seq_length_\" + str(sequence_length)\n",
    "        file_name = \"epochs_\" + str(epochs) +\"_samp_length_\" + str(sample_length) + \"_seq_length_\" + str(sequence_length) + \"_\" + str(song)+\".csv\"\n",
    "        export_list(generated_songs[song], file_name,dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/40\n",
      "44/44 [==============================] - 144s 3s/step - loss: 4.8550\n",
      "Epoch 2/40\n",
      "44/44 [==============================] - 142s 3s/step - loss: 4.6296\n",
      "Epoch 3/40\n",
      "44/44 [==============================] - 147s 3s/step - loss: 4.6080\n",
      "Epoch 4/40\n",
      "44/44 [==============================] - 143s 3s/step - loss: 4.5979\n",
      "Epoch 5/40\n",
      "44/44 [==============================] - 143s 3s/step - loss: 4.5943\n",
      "Epoch 6/40\n",
      "44/44 [==============================] - 143s 3s/step - loss: 4.5796\n",
      "Epoch 7/40\n",
      "44/44 [==============================] - 148s 3s/step - loss: 4.5473\n",
      "Epoch 8/40\n",
      "44/44 [==============================] - 145s 3s/step - loss: 4.8483\n",
      "Epoch 9/40\n",
      "44/44 [==============================] - 150s 3s/step - loss: 4.5782\n",
      "Epoch 10/40\n",
      "44/44 [==============================] - 148s 3s/step - loss: 4.3763\n",
      "Epoch 11/40\n",
      "44/44 [==============================] - 155s 4s/step - loss: 4.3120\n",
      "Epoch 12/40\n",
      "44/44 [==============================] - 153s 3s/step - loss: 4.2610\n",
      "Epoch 13/40\n",
      "44/44 [==============================] - 151s 3s/step - loss: 4.3886\n",
      "Epoch 14/40\n",
      "44/44 [==============================] - 151s 3s/step - loss: 4.1807\n",
      "Epoch 15/40\n",
      "44/44 [==============================] - 150s 3s/step - loss: 4.1084\n",
      "Epoch 16/40\n",
      "44/44 [==============================] - 149s 3s/step - loss: 4.0385\n",
      "Epoch 17/40\n",
      "44/44 [==============================] - 146s 3s/step - loss: 3.9617\n",
      "Epoch 18/40\n",
      "44/44 [==============================] - 152s 3s/step - loss: 3.8645\n",
      "Epoch 19/40\n",
      "44/44 [==============================] - 147s 3s/step - loss: 3.7776\n",
      "Epoch 20/40\n",
      "44/44 [==============================] - 143s 3s/step - loss: 3.6765\n",
      "Epoch 21/40\n",
      "44/44 [==============================] - 149s 3s/step - loss: 3.5518\n",
      "Epoch 22/40\n",
      "44/44 [==============================] - 152s 3s/step - loss: 3.4811\n",
      "Epoch 23/40\n",
      "44/44 [==============================] - 153s 3s/step - loss: 3.3191\n",
      "Epoch 24/40\n",
      "44/44 [==============================] - 151s 3s/step - loss: 3.2082\n",
      "Epoch 25/40\n",
      "44/44 [==============================] - 147s 3s/step - loss: 3.1101\n",
      "Epoch 26/40\n",
      "44/44 [==============================] - 143s 3s/step - loss: 2.9766\n",
      "Epoch 27/40\n",
      "44/44 [==============================] - 147s 3s/step - loss: 2.8754\n",
      "Epoch 28/40\n",
      "44/44 [==============================] - 149s 3s/step - loss: 2.7378\n",
      "Epoch 29/40\n",
      "44/44 [==============================] - 152s 3s/step - loss: 2.6339\n",
      "Epoch 30/40\n",
      "44/44 [==============================] - 158s 4s/step - loss: 2.5341\n",
      "Epoch 31/40\n",
      "44/44 [==============================] - 157s 4s/step - loss: 2.4293\n",
      "Epoch 32/40\n",
      "44/44 [==============================] - 160s 4s/step - loss: 2.3288\n",
      "Epoch 33/40\n",
      "44/44 [==============================] - 160s 4s/step - loss: 2.2185\n",
      "Epoch 34/40\n",
      "44/44 [==============================] - 159s 4s/step - loss: 2.1617\n",
      "Epoch 35/40\n",
      "44/44 [==============================] - 162s 4s/step - loss: 2.0637\n",
      "Epoch 36/40\n",
      "44/44 [==============================] - 150s 3s/step - loss: 1.9710\n",
      "Epoch 37/40\n",
      "44/44 [==============================] - 145s 3s/step - loss: 1.8748\n",
      "Epoch 38/40\n",
      "44/44 [==============================] - 153s 3s/step - loss: 1.8103\n",
      "Epoch 39/40\n",
      "44/44 [==============================] - 151s 3s/step - loss: 1.7161\n",
      "Epoch 40/40\n",
      "44/44 [==============================] - 150s 3s/step - loss: 1.6544\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/40\n",
      "43/43 [==============================] - 270s 6s/step - loss: 4.8718\n",
      "Epoch 2/40\n",
      "43/43 [==============================] - 278s 6s/step - loss: 4.6131\n",
      "Epoch 3/40\n",
      "43/43 [==============================] - 291s 7s/step - loss: 4.4957\n",
      "Epoch 4/40\n",
      "43/43 [==============================] - 283s 7s/step - loss: 4.4039\n",
      "Epoch 5/40\n",
      "43/43 [==============================] - 295s 7s/step - loss: 4.3038\n",
      "Epoch 6/40\n",
      "43/43 [==============================] - 287s 7s/step - loss: 4.2466\n",
      "Epoch 7/40\n",
      "43/43 [==============================] - 288s 7s/step - loss: 4.1697\n",
      "Epoch 8/40\n",
      "43/43 [==============================] - 275s 6s/step - loss: 4.0665\n",
      "Epoch 9/40\n",
      "43/43 [==============================] - 273s 6s/step - loss: 4.0268\n",
      "Epoch 10/40\n",
      "43/43 [==============================] - 267s 6s/step - loss: 3.8911\n",
      "Epoch 11/40\n",
      "43/43 [==============================] - 273s 6s/step - loss: 3.8197\n",
      "Epoch 12/40\n",
      "43/43 [==============================] - 240s 6s/step - loss: 3.8109\n",
      "Epoch 13/40\n",
      "43/43 [==============================] - 241s 6s/step - loss: 3.5940\n",
      "Epoch 14/40\n",
      "43/43 [==============================] - 245s 6s/step - loss: 3.5280\n",
      "Epoch 15/40\n",
      "43/43 [==============================] - 253s 6s/step - loss: 3.4289\n",
      "Epoch 16/40\n",
      "43/43 [==============================] - 280s 7s/step - loss: 3.3961\n",
      "Epoch 17/40\n",
      "43/43 [==============================] - 265s 6s/step - loss: 3.2160\n",
      "Epoch 18/40\n",
      "43/43 [==============================] - 242s 6s/step - loss: 3.1253\n",
      "Epoch 19/40\n",
      "43/43 [==============================] - 241s 6s/step - loss: 3.0271\n",
      "Epoch 20/40\n",
      "43/43 [==============================] - 242s 6s/step - loss: 2.9145\n",
      "Epoch 21/40\n",
      "43/43 [==============================] - 241s 6s/step - loss: 2.8271\n",
      "Epoch 22/40\n",
      "43/43 [==============================] - 260s 6s/step - loss: 2.7343\n",
      "Epoch 23/40\n",
      "43/43 [==============================] - 259s 6s/step - loss: 2.6188\n",
      "Epoch 24/40\n",
      "43/43 [==============================] - 259s 6s/step - loss: 2.5301\n",
      "Epoch 25/40\n",
      "43/43 [==============================] - 262s 6s/step - loss: 2.4273\n",
      "Epoch 26/40\n",
      "43/43 [==============================] - 256s 6s/step - loss: 2.3224\n",
      "Epoch 27/40\n",
      "43/43 [==============================] - 260s 6s/step - loss: 2.2414\n",
      "Epoch 28/40\n",
      "43/43 [==============================] - 264s 6s/step - loss: 2.1668\n",
      "Epoch 29/40\n",
      "43/43 [==============================] - 273s 6s/step - loss: 2.0735\n",
      "Epoch 30/40\n",
      "43/43 [==============================] - 256s 6s/step - loss: 2.0402\n",
      "Epoch 31/40\n",
      "43/43 [==============================] - 260s 6s/step - loss: 1.9446\n",
      "Epoch 32/40\n",
      "43/43 [==============================] - 265s 6s/step - loss: 1.8718\n",
      "Epoch 33/40\n",
      "43/43 [==============================] - 262s 6s/step - loss: 1.8180\n",
      "Epoch 34/40\n",
      "43/43 [==============================] - 270s 6s/step - loss: 1.7622\n",
      "Epoch 35/40\n",
      "43/43 [==============================] - 260s 6s/step - loss: 1.6868\n",
      "Epoch 36/40\n",
      "43/43 [==============================] - 259s 6s/step - loss: 1.6318\n",
      "Epoch 37/40\n",
      "43/43 [==============================] - 249s 6s/step - loss: 1.5878\n",
      "Epoch 38/40\n",
      "43/43 [==============================] - 260s 6s/step - loss: 1.5552\n",
      "Epoch 39/40\n",
      "43/43 [==============================] - 264s 6s/step - loss: 1.4589\n",
      "Epoch 40/40\n",
      "43/43 [==============================] - 272s 6s/step - loss: 1.4264\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "data_dir = r\"C:\\Users\\alext\\Desktop\\School\\2021 Spring\\CS 271\\Final Project\\Feature Extraction\\Jazz\\Jazz Extracted Notes (Solo Treble Only)\"\n",
    "\n",
    "num_songs = 20\n",
    "epochs = 40\n",
    "\n",
    "sample_legths = [1000, 2000, 3000]\n",
    "sequence_lengths = [10, 50, 100, 200, 300]\n",
    "\n",
    "# Generate songs\n",
    "for sample_len in sample_legths:\n",
    "    for seq_len in sequence_lengths:\n",
    "        generate_songs(sample_len, data_dir, seq_len, epochs, num_songs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
